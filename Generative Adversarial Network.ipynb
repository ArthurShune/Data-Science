{"nbformat_minor": 1, "cells": [{"source": "MIT License\n\nCopyright (c) 2017 Erik Linder-Nor\u00e9n\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.", "cell_type": "markdown", "metadata": {}}, {"source": "#Please make sure you have at least TensorFlow version 1.12 installed, if not please uncomment and use the \n# pip command below to upgrade. When in a jupyter environment (especially IBM Watson Studio),\n# please don't forget to restart the kernel\nimport tensorflow as tf\ntf.__version__", "cell_type": "code", "execution_count": 1, "outputs": [{"output_type": "execute_result", "metadata": {}, "data": {"text/plain": "'1.13.1'"}, "execution_count": 1}], "metadata": {}}, {"source": "!pip install --upgrade tensorflow", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "from __future__ import print_function, division\n\nfrom keras.datasets import mnist\nfrom keras.layers import Input, Dense, Reshape, Flatten, Dropout\nfrom keras.layers import BatchNormalization, Activation, ZeroPadding2D\nfrom keras.layers.advanced_activations import LeakyReLU\nfrom keras.layers.convolutional import UpSampling2D, Conv2D\nfrom keras.models import Sequential, Model\nfrom keras.optimizers import Adam\n\nimport matplotlib.pyplot as plt\n\nimport sys\n\nimport numpy as np", "cell_type": "code", "execution_count": 2, "outputs": [{"output_type": "stream", "name": "stderr", "text": "Using TensorFlow backend.\n"}], "metadata": {}}, {"source": "img_rows = 28\nimg_cols = 28\nchannels = 1\nlatent_dim = 100\nimg_shape = (img_rows, img_cols, channels)", "cell_type": "code", "execution_count": 3, "outputs": [], "metadata": {}}, {"source": "def build_generator():\n\n    model = Sequential()\n\n    model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=latent_dim))\n    model.add(Reshape((7, 7, 128)))\n    model.add(UpSampling2D())\n    model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(UpSampling2D())\n    model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(Activation(\"relu\"))\n    model.add(Conv2D(channels, kernel_size=3, padding=\"same\"))\n    model.add(Activation(\"tanh\"))\n\n    model.summary()\n\n    noise = Input(shape=(latent_dim,))\n    img = model(noise)\n\n    return Model(noise, img)", "cell_type": "code", "execution_count": 4, "outputs": [], "metadata": {}}, {"source": "def build_discriminator():\n\n    model = Sequential()\n\n    model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=img_shape, padding=\"same\"))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n    model.add(BatchNormalization(momentum=0.8))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(1, activation='sigmoid'))\n\n    model.summary()\n\n    img = Input(shape=img_shape)\n    validity = model(img)\n\n    return Model(img, validity)", "cell_type": "code", "execution_count": 5, "outputs": [], "metadata": {}}, {"source": "\n\noptimizer = Adam(0.0002, 0.5)\n\n# Build and compile the discriminator\ndiscriminator = build_discriminator()\ndiscriminator.compile(loss='binary_crossentropy',\n    optimizer=optimizer,\n    metrics=['accuracy'])\n\n# Build the generator\ngenerator = build_generator()\n\n# The generator takes noise as input and generates imgs\nz = Input(shape=(latent_dim,))\nimg = generator(z)\n\n# For the combined model we will only train the generator\ndiscriminator.trainable = False\n\n# The discriminator takes generated images as input and determines validity\nvalid = discriminator(img)\n\n# The combined model  (stacked generator and discriminator)\n# Trains the generator to fool the discriminator\ncombined = Model(z, valid)\ncombined.compile(loss='binary_crossentropy', optimizer=optimizer)", "cell_type": "code", "execution_count": 6, "outputs": [{"output_type": "stream", "name": "stdout", "text": "WARNING:tensorflow:From /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nWARNING:tensorflow:From /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3135: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_1 (Conv2D)            (None, 14, 14, 32)        320       \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 14, 14, 32)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 14, 14, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 7, 7, 64)          18496     \n_________________________________________________________________\nzero_padding2d_1 (ZeroPaddin (None, 8, 8, 64)          0         \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 8, 8, 64)          256       \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 8, 8, 64)          0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 4, 4, 128)         73856     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 4, 4, 128)         512       \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 4, 4, 128)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 4, 4, 256)         295168    \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 4, 4, 256)         1024      \n_________________________________________________________________\nleaky_re_lu_4 (LeakyReLU)    (None, 4, 4, 256)         0         \n_________________________________________________________________\ndropout_4 (Dropout)          (None, 4, 4, 256)         0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 4096)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 4097      \n=================================================================\nTotal params: 393,729\nTrainable params: 392,833\nNon-trainable params: 896\n_________________________________________________________________\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_2 (Dense)              (None, 6272)              633472    \n_________________________________________________________________\nreshape_1 (Reshape)          (None, 7, 7, 128)         0         \n_________________________________________________________________\nup_sampling2d_1 (UpSampling2 (None, 14, 14, 128)       0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 14, 14, 128)       147584    \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 14, 14, 128)       512       \n_________________________________________________________________\nactivation_1 (Activation)    (None, 14, 14, 128)       0         \n_________________________________________________________________\nup_sampling2d_2 (UpSampling2 (None, 28, 28, 128)       0         \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, 28, 28, 64)        73792     \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 28, 28, 64)        256       \n_________________________________________________________________\nactivation_2 (Activation)    (None, 28, 28, 64)        0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 28, 28, 1)         577       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 28, 28, 1)         0         \n=================================================================\nTotal params: 856,193\nTrainable params: 855,809\nNon-trainable params: 384\n_________________________________________________________________\n"}], "metadata": {}}, {"source": "def save_imgs(epoch):\n    r, c = 5, 5\n    noise = np.random.normal(0, 1, (r * c, latent_dim))\n    gen_imgs = generator.predict(noise)\n\n    # Rescale images 0 - 1\n    gen_imgs = 0.5 * gen_imgs + 0.5\n\n    fig, axs = plt.subplots(r, c)\n    cnt = 0\n    for i in range(r):\n        for j in range(c):\n            axs[i,j].imshow(gen_imgs[cnt, :,:,0], cmap='gray')\n            axs[i,j].axis('off')\n            cnt += 1\n    fig.savefig(\"images/mnist_%d.png\" % epoch)\n    plt.close()", "cell_type": "code", "execution_count": 7, "outputs": [], "metadata": {}}, {"source": "def train(epochs, batch_size=128, save_interval=50):\n\n    # Load the dataset\n    (X_train, _), (_, _) = mnist.load_data()\n\n    # Rescale -1 to 1\n    X_train = X_train / 127.5 - 1.\n    X_train = np.expand_dims(X_train, axis=3)\n\n    # Adversarial ground truths\n    valid = np.ones((batch_size, 1))\n    fake = np.zeros((batch_size, 1))\n\n    for epoch in range(epochs):\n\n        # ---------------------\n        #  Train Discriminator\n        # ---------------------\n\n        # Select a random half of images\n        idx = np.random.randint(0, X_train.shape[0], batch_size)\n        imgs = X_train[idx]\n\n        # Sample noise and generate a batch of new images\n        noise = np.random.normal(0, 1, (batch_size, latent_dim))\n        gen_imgs = generator.predict(noise)\n\n        # Train the discriminator (real classified as ones and generated as zeros)\n        d_loss_real = discriminator.train_on_batch(imgs, valid)\n        d_loss_fake = discriminator.train_on_batch(gen_imgs, fake)\n        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n\n        # ---------------------\n        #  Train Generator\n        # ---------------------\n\n        # Train the generator (wants discriminator to mistake images as real)\n        g_loss = combined.train_on_batch(noise, valid)\n\n        # Plot the progress\n        print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n\n        # If at save interval => save generated image samples\n        if epoch % save_interval == 0:\n            save_imgs(epoch)", "cell_type": "code", "execution_count": 8, "outputs": [], "metadata": {}}, {"source": "!mkdir -p images", "cell_type": "code", "execution_count": 9, "outputs": [], "metadata": {}}, {"source": "train(epochs=4000, batch_size=32, save_interval=50)", "cell_type": "code", "execution_count": null, "outputs": [{"output_type": "stream", "name": "stdout", "text": "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n11493376/11490434 [==============================] - 1s 0us/step\nWARNING:tensorflow:From /opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"}, {"output_type": "stream", "name": "stderr", "text": "/opt/conda/envs/DSX-Python35/lib/python3.5/site-packages/keras/engine/training.py:973: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n  'Discrepancy between trainable weights and collected trainable'\n"}, {"output_type": "stream", "name": "stdout", "text": "0 [D loss: 0.937897, acc.: 37.50%] [G loss: 0.887703]\n1 [D loss: 0.502372, acc.: 71.88%] [G loss: 1.458619]\n2 [D loss: 0.364257, acc.: 85.94%] [G loss: 1.818128]\n3 [D loss: 0.246759, acc.: 93.75%] [G loss: 2.516551]\n4 [D loss: 0.214292, acc.: 90.62%] [G loss: 2.229688]\n5 [D loss: 0.222132, acc.: 93.75%] [G loss: 2.083037]\n"}], "metadata": {}}, {"source": "ls images", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "from IPython.display import display\nfrom PIL import Image\n\n\npath=\"images/mnist_0.png\"\ndisplay(Image.open(path))", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}, {"source": "\nfrom IPython.display import display\nfrom PIL import Image\n\n\npath=\"images/mnist_3950.png\"\ndisplay(Image.open(path))", "cell_type": "code", "execution_count": null, "outputs": [], "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"display_name": "Python 3.5", "name": "python3", "language": "python"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "version": "3.5.5", "name": "python", "file_extension": ".py", "pygments_lexer": "ipython3", "codemirror_mode": {"version": 3, "name": "ipython"}}}}